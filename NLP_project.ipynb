{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/fezilemahlangu/Natural-Language-Processing-Project/blob/main/NLP_project.ipynb",
      "authorship_tag": "ABX9TyPVcdJbHCnaNcYxUdxDu83o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fezilemahlangu/Natural-Language-Processing-Project/blob/main/NLP_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fezile Mahlangu \n",
        "\n",
        "#2089676\n",
        "\n",
        "#NLP Project \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Project: Spam Classification Using Naive Bayes\n",
        "\n",
        "Aim: Train and optimize a spam classifier using Naive Bayes classification model\n",
        "\n",
        "Tasks:\n",
        "- [x] Implement a Naive Bayes Model\n",
        "- [ ] Investigate the effect of using different features \n",
        "- [ ] Evaluate the performance of different models\n",
        "- [ ] Optimize the model for better performance\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0Y1HgjYg_FCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qb81hvjKNksD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hCYvB5ipLtJ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "S33aocZe-etl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec545c34-9473-4192-c1f4-ce60d07b51ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import copy\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "nltk.download(\"wordnet\")\n",
        "from nltk.stem.wordnet import WordNetLemmatizer \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix,f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data"
      ],
      "metadata": {
        "id": "yEImhTNLLwU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data -> Remember to remove drive path and use normal path\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/NLP/train.csv\")\n",
        "val_df = pd.read_csv(\"/content/drive/MyDrive/NLP/val.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/NLP/test.csv\")\n",
        "display(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GCpy9615-sCa",
        "outputId": "c1eb644a-862c-4b2c-c3ac-384612a8067d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     Subject: thank you\\r\\nami and daren , , , ,\\r\\...      0\n",
              "1     Subject: spot or firm tickets\\r\\nvance ,\\r\\nth...      0\n",
              "2     Subject: software\\r\\nmicrosoft windows xp prof...      1\n",
              "3     Subject: noms / actual flow for 2 / 27\\r\\nwe a...      0\n",
              "4     Subject: superb so . ftware\\r\\nyoull discover ...      1\n",
              "...                                                 ...    ...\n",
              "3097  Subject: \\r\\n( envelope - from 20040929124340 ...      1\n",
              "3098  Subject: re : intraday eastrans nomination cha...      0\n",
              "3099  Subject: meter 1601\\r\\ndaren - meter 1601 has ...      0\n",
              "3100  Subject: need legal help ?\\r\\nto unsubscribe f...      1\n",
              "3101  Subject: re : tuesday , december 26 th\\r\\nmary...      0\n",
              "\n",
              "[3102 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c34e68e4-a4d1-48ac-befe-cd6d6c044db2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: thank you\\r\\nami and daren , , , ,\\r\\...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: spot or firm tickets\\r\\nvance ,\\r\\nth...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: software\\r\\nmicrosoft windows xp prof...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: noms / actual flow for 2 / 27\\r\\nwe a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: superb so . ftware\\r\\nyoull discover ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3097</th>\n",
              "      <td>Subject: \\r\\n( envelope - from 20040929124340 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3098</th>\n",
              "      <td>Subject: re : intraday eastrans nomination cha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3099</th>\n",
              "      <td>Subject: meter 1601\\r\\ndaren - meter 1601 has ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3100</th>\n",
              "      <td>Subject: need legal help ?\\r\\nto unsubscribe f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3101</th>\n",
              "      <td>Subject: re : tuesday , december 26 th\\r\\nmary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3102 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c34e68e4-a4d1-48ac-befe-cd6d6c044db2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c34e68e4-a4d1-48ac-befe-cd6d6c044db2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c34e68e4-a4d1-48ac-befe-cd6d6c044db2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train = [train_df[train_df.label==0].count()[0],train_df[train_df.label==1].count()[0]]\n",
        "test = [test_df[test_df.label==0].count()[0],test_df[test_df.label==1].count()[0]]\n",
        "val = [val_df[val_df.label==0].count()[0],val_df[val_df.label==1].count()[0]]\n",
        "\n",
        "index = ['0', '1']\n",
        "df = pd.DataFrame({'train': train,\n",
        "                   'val': val, 'test':test}, index=index)\n",
        "ax = df.plot.bar(rot=0)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "eDCHvHPgHmrL",
        "outputId": "8a20ddd8-f38e-4df6-c9f1-bffa31966a4c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing of data\n",
        "\n",
        "The text will be tokenized and there will be a list of words for each sentence "
      ],
      "metadata": {
        "id": "RzdMP6ioIwVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8AYW_3jUqRBu",
        "outputId": "9bc80ac4-d5ed-4ce5-a693-73f666730e07"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Subject: thank you\\r\\nami and daren , , , ,\\r\\...      0\n",
              "1  Subject: spot or firm tickets\\r\\nvance ,\\r\\nth...      0\n",
              "2  Subject: software\\r\\nmicrosoft windows xp prof...      1\n",
              "3  Subject: noms / actual flow for 2 / 27\\r\\nwe a...      0\n",
              "4  Subject: superb so . ftware\\r\\nyoull discover ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a753bb0-6dba-4537-a8ce-51bd4ef2a9ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: thank you\\r\\nami and daren , , , ,\\r\\...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: spot or firm tickets\\r\\nvance ,\\r\\nth...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: software\\r\\nmicrosoft windows xp prof...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: noms / actual flow for 2 / 27\\r\\nwe a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: superb so . ftware\\r\\nyoull discover ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a753bb0-6dba-4537-a8ce-51bd4ef2a9ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a753bb0-6dba-4537-a8ce-51bd4ef2a9ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a753bb0-6dba-4537-a8ce-51bd4ef2a9ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating x and y from dataframes \n",
        "train_x = train_df.text\n",
        "train_y = train_df.label\n",
        "\n",
        "test_x = test_df.text\n",
        "test_y = test_df.label\n",
        "\n",
        "val_x = val_df.text\n",
        "val_y = val_df.label\n",
        "\n",
        "len(train_x)\n",
        "\n",
        "# https://www.kaggle.com/code/conniedeng/nlp-eron-dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gWGRy7mDkJy",
        "outputId": "d7565e53-b458-47b4-a8cb-090ed0efb53a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3102"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_row(row):\n",
        "  #splits row by \"\\n\"\n",
        "  return row.split(\"\\n\")"
      ],
      "metadata": {
        "id": "Xex94GysrZ3D"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(row):\n",
        "  #splits by white space and punct \n",
        "  return wordpunct_tokenize(row)"
      ],
      "metadata": {
        "id": "Zv0rAhQfs32u"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_money(row):\n",
        "  #puts $5.99 back from [\"$\",\"5\",\".\",\"99\"]\n",
        "  leng = len(row)\n",
        "  i = 0\n",
        "  while leng != 0 :\n",
        "    if row[i]=='$' and row[i+2].isnumeric():\n",
        "      row = row[:i+1] + row[(i+2):]\n",
        "      leng-=1\n",
        "\n",
        "    elif (row[i] == '.' and row[i+2].isnumeric() and row[i-2].isnumeric()):\n",
        "      row = row[0:i-1] + row[i:i+1] + row[i+2:]\n",
        "      leng-=2\n",
        "    i+=1\n",
        "    leng-=1\n",
        "\n",
        "  return row\n",
        "  "
      ],
      "metadata": {
        "id": "KaPdbzTDt8hX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def handle_hyperlinks(row):\n",
        "#   for i in range(len(row)):\n",
        "#     if row[i] == \"http\" or row[i] == \"https\"\n",
        "\n",
        "\n",
        "    \n",
        "#     if row[i] == \"com\":\n",
        "#       row[i] = row[i-2] +row[i-1] +  row[i] \n",
        "#       print(row)\n",
        "#       print(\"deleting\")\n",
        "#       del row[i-1]\n",
        "#       del row[i-2]\n",
        "#   return row\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xuOIf-r3y4ON"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punct(row):\n",
        "  #romoves punctuation marks \n",
        "  # [word for word in row if word.isalpha() or word[0] == \"$\" or word==\"!\"] \n",
        "\n",
        "  return [word for word in row if word.isalpha()] #check this thos \n"
      ],
      "metadata": {
        "id": "KOW_iddhKZif"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.stem.porter.PorterStemmer()\n",
        "def stem_words(row):\n",
        "  #function that performs stemming \n",
        "  # removes word ending crudely -ing \n",
        "  return [stemmer.stem(i) for i in row]\n"
      ],
      "metadata": {
        "id": "O_MfO-43K49-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "def lemmatize(row):\n",
        "  #performs lemmatization \n",
        "  # make a word a root \n",
        "  return [lemmatizer.lemmatize(i) for i in row]"
      ],
      "metadata": {
        "id": "cFU9diFRLL8c"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [\"getting\", \"google\", \"meeting\",\"rocks\"]\n",
        "\n",
        "lemmatize(a)\n",
        "\n",
        "# stem_words(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYwj9I_yNOwW",
        "outputId": "1348b665-a525-422f-c15a-66b3cf958e86"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['getting', 'google', 'meeting', 'rock']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
        "\n",
        "def tokenize_with_money(row):\n",
        "  #dont split if theres money \n",
        "  return tokenizer.tokenize(row)\n"
      ],
      "metadata": {
        "id": "7XLgrj4Q_OeC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def remove_stop_words(row):\n",
        "  #removes stop words -> really frequent words  \n",
        "  return [i for i in row if i not in stop_words]"
      ],
      "metadata": {
        "id": "ssoxShzqJZN5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_x[2])\n",
        "# # a = split_row(train_x[0])\n",
        "# # print(a)\n",
        "# # \n",
        "# a = handle_money(train_x[2])\n",
        "\n",
        "# print(a)\n",
        "# print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "# a = tokenize_with_money(a)\n",
        "# print(a)\n",
        "# print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "# a = remove_punct(a)\n",
        "# print(a)\n",
        "# print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "# a = remove_stop_words(a)\n",
        "# print(a)\n",
        "# print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "# a = stem_words(a)\n",
        "# print(a)\n",
        "# print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "# a = lemmatize(a)\n",
        "# print(a)\n",
        "# print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "ZATFP1x5ulex"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_x(data):\n",
        "  clean = []\n",
        "  for i in data:\n",
        "    text = tokenize_with_money(i)\n",
        "\n",
        "    text = remove_punct(text)\n",
        "\n",
        "    text = remove_stop_words(text)\n",
        "\n",
        "    text = stem_words(text)\n",
        "\n",
        "    text = lemmatize(text)\n",
        "\n",
        "    clean.append(text)\n",
        "  return clean \n",
        "\n"
      ],
      "metadata": {
        "id": "-rKPv2TWUHot"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clean_train_x = clean_x(train_x)\n",
        "clean_val_x = clean_x(val_x)\n",
        "clean_test_x = clean_x(test_x)\n"
      ],
      "metadata": {
        "id": "4E018dbz4uui"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text before preprocessing: \\n\")\n",
        "print(train_x[0])\n",
        "print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"Text after preprocessing: \\n\")\n",
        "print(clean_train_x[0])\n",
        "print(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOsXSKA3Mp_C",
        "outputId": "0cf7aca8-213b-4cb8-ba94-6db513a6485f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before preprocessing: \n",
            "\n",
            "Subject: thank you\r\n",
            "ami and daren , , , ,\r\n",
            "just wanted again to say thanks ! ! ! , for the great time at st . pete ' s beach ,\r\n",
            "fla .\r\n",
            "the company , food , fishing and yes , of coarse\r\n",
            "the drink or many drinks were great ! ! ! daren , can relate to the drinks .\r\n",
            "i enjoyed meeting everyone there .\r\n",
            "we appreciate your business and look forward to continue our business relation\r\n",
            "with enron in the future .\r\n",
            "sincerely ,\r\n",
            "tim\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Text after preprocessing: \n",
            "\n",
            "['subject', 'thank', 'ami', 'daren', 'want', 'say', 'thank', 'great', 'time', 'st', 'pete', 'beach', 'fla', 'compani', 'food', 'fish', 'ye', 'coars', 'drink', 'mani', 'drink', 'great', 'daren', 'relat', 'drink', 'enjoy', 'meet', 'everyon', 'appreci', 'busi', 'look', 'forward', 'continu', 'busi', 'relat', 'enron', 'futur', 'sincer', 'tim']\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing hyperlinks "
      ],
      "metadata": {
        "id": "Fk7DO2ZTxky8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_x[10])"
      ],
      "metadata": {
        "id": "dWj5cxCii4W7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a standard Naive Bayes model "
      ],
      "metadata": {
        "id": "62EkfrNSDDZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #scale data ?\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# sc = StandardScaler()\n",
        "\n",
        "# x_train is after count_vector.fit \n",
        "# x_train = sc.fit_transform(x_train)\n",
        "# x_test = sc.transform(x_test)\n",
        "\n",
        "#LAPLACE SMOOTHING "
      ],
      "metadata": {
        "id": "fKTthfXA3Y5U"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming to numeric form for MultinomialNB\n",
        "\n",
        "count_vector = CountVectorizer()\n",
        "\n",
        "clean_train_x_join = [\" \".join(i) for i in clean_train_x] #turn to string for count_vector \n",
        "\n",
        "\n",
        "trans_x = count_vector.fit_transform(clean_train_x_join)\n",
        "\n",
        "trans_x_dense = np.array(trans_x.todense())\n",
        "\n",
        "Model1 = MultinomialNB().fit(trans_x_dense,train_y) #multi ???"
      ],
      "metadata": {
        "id": "bVVD5uQxDC4g"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trans_x[0][0]\n",
        "# https://www.kaggle.com/code/syamalakumar/spam-ham-nlp-basic-project\n",
        "\n",
        "# https://www.kaggle.com/code/dilip990/spam-ham-detection-using-naive-bayes-classifier\n",
        "\n",
        "# https://www.kaggle.com/code/conniedeng/nlp-eron-dataset\n",
        "\n",
        "\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "\n",
        "# https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html\n",
        "\n"
      ],
      "metadata": {
        "id": "KHdi4bjGTqln"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes model using 10 most frequent words as features "
      ],
      "metadata": {
        "id": "xNL_HvDLDTr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_clean_x = []\n",
        "for arr in clean_train_x:\n",
        "  for i in range(1,len(arr)): #doesnt include \"subject\" \n",
        "      # print(arr[i])\n",
        "      all_clean_x.append(arr[i])"
      ],
      "metadata": {
        "id": "hxZLAIZ6gnNK"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_clean_x[0:50]) #doesnt inlcude subject"
      ],
      "metadata": {
        "id": "x-JCtt61Xvcj",
        "outputId": "ed87a1b5-262a-47ce-dd13-7bc97d1ccc96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thank', 'ami', 'daren', 'want', 'say', 'thank', 'great', 'time', 'st', 'pete', 'beach', 'fla', 'compani', 'food', 'fish', 'ye', 'coars', 'drink', 'mani', 'drink', 'great', 'daren', 'relat', 'drink', 'enjoy', 'meet', 'everyon', 'appreci', 'busi', 'look', 'forward', 'continu', 'busi', 'relat', 'enron', 'futur', 'sincer', 'tim', 'spot', 'firm', 'ticket', 'vanc', 'follow', 'nomin', 'deal', 'ticket', 'sitara', 'septemb', 'activ', 'plea']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get top 10 features using counter \n",
        "Counter = Counter(all_clean_x)\n",
        "\n",
        "top10 = Counter.most_common(10)\n",
        "\n",
        "print(top10)\n",
        "  \n",
        "# print(most_occur)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sWD-0XnDNYf",
        "outputId": "7eabe930-791f-43ec-9a35-4f201b53e39f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ect', 8343), ('hou', 4376), ('enron', 3908), ('com', 2452), ('deal', 2200), ('plea', 1892), ('ga', 1794), ('subject', 1674), ('meter', 1569), ('hpl', 1404)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_dictionary=[]\n",
        "for i in top10:\n",
        "  top_10_dictionary.append(i[0])\n",
        "print(top_10_dictionary)\n"
      ],
      "metadata": {
        "id": "eiWrM3WJB2nQ",
        "outputId": "9e05fc68-34b5-4054-ae71-14e73ed096d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ect', 'hou', 'enron', 'com', 'deal', 'plea', 'ga', 'subject', 'meter', 'hpl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top10_train_x = []\n",
        "# top10_train_x[0]\n",
        "for arr in clean_train_x:\n",
        "  new_arr = []\n",
        "  for word in arr:\n",
        "    if word in top_10_dictionary:\n",
        "      new_arr.append(word)\n",
        "  top10_train_x.append(new_arr)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jj0MR4fmSk-v"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  len(clean_train_x) == len(top10_train_x)\n",
        "except:\n",
        "  print(\"lengths do not match \")"
      ],
      "metadata": {
        "id": "XYrL4diOcUl4"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First element clean:\")\n",
        "print(clean_train_x[0])\n",
        "print(\"First element with top 10 features:\")\n",
        "print(top10_train_x[0])\n",
        "print(\"--------------------------------------------------------------------\")\n",
        "print(\"Second element clean:\")\n",
        "print(clean_train_x[1])\n",
        "print(\"Second element with top 10 features:\")\n",
        "print(top10_train_x[1])\n",
        "print(\"--------------------------------------------------------------------\")\n",
        "print(\"Third element clean:\")\n",
        "print(clean_train_x[2])\n",
        "print(\"Third element with top 10 features:\")\n",
        "print(top10_train_x[2])"
      ],
      "metadata": {
        "id": "3f9390miWm1F",
        "outputId": "966a3277-1150-4a05-9ace-1bfb0cc4ecc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First element clean:\n",
            "['subject', 'thank', 'ami', 'daren', 'want', 'say', 'thank', 'great', 'time', 'st', 'pete', 'beach', 'fla', 'compani', 'food', 'fish', 'ye', 'coars', 'drink', 'mani', 'drink', 'great', 'daren', 'relat', 'drink', 'enjoy', 'meet', 'everyon', 'appreci', 'busi', 'look', 'forward', 'continu', 'busi', 'relat', 'enron', 'futur', 'sincer', 'tim']\n",
            "First element with top 10 features:\n",
            "['subject', 'enron']\n",
            "--------------------------------------------------------------------\n",
            "Second element clean:\n",
            "['subject', 'spot', 'firm', 'ticket', 'vanc', 'follow', 'nomin', 'deal', 'ticket', 'sitara', 'septemb', 'activ', 'plea', 'advis', 'whether', 'deal', 'spot', 'firm', 'daren', 'want', 'everyth', 'sitara', 'pm', 'monday', 'august', 'thank', 'bob', 'sourc', 'meter', 'sept', 'nom', 'ccgm', 'lp', 'cross', 'tex', 'cummin', 'walker', 'unk', 'dalla', 'product', 'duke', 'energi', 'trade', 'eex', 'oper', 'eog', 'resourc', 'hesco', 'gather', 'hesco', 'gather', 'ph', 'explor', 'pioneer', 'explor', 'pure', 'resourc', 'rio', 'vista', 'samson', 'lonestar', 'swift', 'energi', 'tema', 'oil', 'ga', 'tri', 'union', 'develop', 'white', 'petroleum']\n",
            "Second element with top 10 features:\n",
            "['subject', 'deal', 'plea', 'deal', 'meter', 'ga']\n",
            "--------------------------------------------------------------------\n",
            "Third element clean:\n",
            "['subject', 'softwar', 'microsoft', 'window', 'xp', 'professiozn', 'retail', 'price', 'low', 'prici', 'save', 'adob', 'photoshkop', 'retail', 'price', 'low', 'price', 'savu', 'microsoft', 'offic', 'xp', 'profession', 'retail', 'price', 'low', 'price', 'savx', 'adob', 'illustr', 'retaitl', 'price', 'low', 'price', 'savx', 'corel', 'draw', 'graphic', 'suit', 'rehtail', 'price', 'low', 'pricj', 'save', 'delphi', 'retaifl', 'price', 'low', 'price', 'save', 'cheap', 'softwar', 'oem', 'meaninag', 'get', 'box', 'manual', 'softwar', 'receivz', 'actual', 'softwar', 'uniqu', 'registr', 'code', 'softwaru', 'english', 'languag', 'pc', 'offer', 'unbeatablk', 'alway', 'updat', 'price', 'make', 'sure', 'provid', 'besft', 'possibl', 'offer', 'hurri', 'place', 'ordner', 'suppli', 'limit', 'visimt', 'u', 'http', 'cheap', 'drug', 'biz', 'oeol', 'affili', 'id', 'campaign', 'id', 'fwunrt', 'fmooetr', 'ltbi', 'nyqkgbphb', 'krgzgl', 'vbbmigb', 'zwftnqlp', 'oaohkv', 'icckmv', 'rmcetdf', 'wmlx', 'lidfxvrnk', 'tdrezc', 'hbmvxft', 'zjqdpnpd', 'ldloti', 'jbywub', 'ozaqgcf', 'czjj', 'yvcbkprnc', 'vbrekd', 'fizzjnz', 'kgfmkhmw', 'rkqumd', 'kgrnbt', 'ggejkmi', 'kyyj', 'jepyoyklp', 'wekjhw', 'pajrtqi', 'ybjlkvjj', 'gvnwte', 'ueqjbv', 'vkcrccd', 'uwut', 'uwdhtzrrf', 'mhbglw', 'jdhkydx', 'bvaeyvat', 'nvorcx', 'qvpwtx', 'yniuzlb', 'kkei', 'lziqyfqqu', 'mhlped', 'kuauryt', 'bthnutaz', 'clzkex', 'pvojiw', 'xaablvb', 'gnao', 'otxenpenr', 'qmdvju', 'qafbwcc', 'xdntfvhf', 'jxzhbn']\n",
            "Third element with top 10 features:\n",
            "['subject']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive base model \n",
        "count_vector = CountVectorizer()\n",
        "\n",
        "top10_train_x_join = [\" \".join(i) for i in top10_train_x] #turn to string for count_vector \n",
        "\n",
        "trans_x = count_vector.fit_transform(top10_train_x_join)\n",
        "\n",
        "trans_x_dense = np.array(trans_x.todense())\n",
        "\n",
        "Model2 = MultinomialNB().fit(trans_x_dense,train_y) #multi ???"
      ],
      "metadata": {
        "id": "7g52gLO71VIr"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes model using 100 most frequent words as features "
      ],
      "metadata": {
        "id": "GFQBM0mvDVXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Counter = Counter(all_clean_x)\n",
        "\n",
        "top100 = Counter.most_common(100)\n",
        "\n",
        "print(top100)\n",
        "\n",
        "top_100_dictionary=[]\n",
        "for i in top100:\n",
        "  top_100_dictionary.append(i[0])\n",
        "print(top_100_dictionary)"
      ],
      "metadata": {
        "id": "JQadP6m3DW8Q",
        "outputId": "e83d73a6-d016-45cc-b634-df223d5b1df0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ect', 8343), ('hou', 4376), ('enron', 3908), ('com', 2452), ('deal', 2200), ('plea', 1892), ('ga', 1794), ('subject', 1674), ('meter', 1569), ('hpl', 1404), ('cc', 1392), ('thank', 1348), ('pm', 1331), ('need', 1249), ('e', 1203), ('daren', 1120), ('forward', 1091), ('price', 1089), ('volum', 1040), ('corp', 1030), ('know', 976), ('day', 950), ('new', 898), ('get', 892), ('compani', 873), ('j', 813), ('may', 806), ('mmbtu', 802), ('product', 800), ('chang', 788), ('see', 771), ('u', 766), ('l', 763), ('http', 756), ('contract', 751), ('inform', 737), ('attach', 713), ('let', 692), ('nom', 676), ('time', 673), ('farmer', 665), ('xl', 658), ('month', 653), ('would', 641), ('sale', 639), ('nomin', 632), ('messag', 618), ('mail', 607), ('one', 603), ('th', 594), ('call', 578), ('flow', 572), ('juli', 571), ('follow', 563), ('use', 561), ('robert', 556), ('question', 551), ('email', 517), ('ticket', 516), ('file', 515), ('net', 515), ('p', 512), ('report', 503), ('want', 500), ('look', 499), ('sitara', 490), ('manag', 489), ('work', 486), ('texa', 481), ('servic', 479), ('list', 476), ('ena', 475), ('energi', 466), ('number', 455), ('also', 453), ('sent', 449), ('purchas', 443), ('www', 438), ('like', 438), ('go', 434), ('busi', 433), ('market', 423), ('x', 413), ('actual', 405), ('pec', 404), ('origin', 400), ('b', 399), ('make', 398), ('contact', 397), ('receiv', 391), ('system', 390), ('bob', 387), ('c', 384), ('order', 378), ('take', 368), ('back', 367), ('help', 363), ('schedul', 362), ('font', 362), ('effect', 359)]\n",
            "['ect', 'hou', 'enron', 'com', 'deal', 'plea', 'ga', 'subject', 'meter', 'hpl', 'cc', 'thank', 'pm', 'need', 'e', 'daren', 'forward', 'price', 'volum', 'corp', 'know', 'day', 'new', 'get', 'compani', 'j', 'may', 'mmbtu', 'product', 'chang', 'see', 'u', 'l', 'http', 'contract', 'inform', 'attach', 'let', 'nom', 'time', 'farmer', 'xl', 'month', 'would', 'sale', 'nomin', 'messag', 'mail', 'one', 'th', 'call', 'flow', 'juli', 'follow', 'use', 'robert', 'question', 'email', 'ticket', 'file', 'net', 'p', 'report', 'want', 'look', 'sitara', 'manag', 'work', 'texa', 'servic', 'list', 'ena', 'energi', 'number', 'also', 'sent', 'purchas', 'www', 'like', 'go', 'busi', 'market', 'x', 'actual', 'pec', 'origin', 'b', 'make', 'contact', 'receiv', 'system', 'bob', 'c', 'order', 'take', 'back', 'help', 'schedul', 'font', 'effect']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top100_train_x = []\n",
        "# top10_train_x[0]\n",
        "for arr in clean_train_x:\n",
        "  new_arr = []\n",
        "  for word in arr:\n",
        "    if word in top_100_dictionary:\n",
        "      new_arr.append(word)\n",
        "  top100_train_x.append(new_arr)"
      ],
      "metadata": {
        "id": "tPIOwfT_iZhj"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  len(clean_train_x) == len(top100_train_x)\n",
        "except:\n",
        "  print(\"lengths do not match \")"
      ],
      "metadata": {
        "id": "GTnRL9WNimVp"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First element clean:\")\n",
        "print(clean_train_x[0])\n",
        "print(\"First element with top 10 features:\")\n",
        "print(top100_train_x[0])\n",
        "print(\"--------------------------------------------------------------------\")\n",
        "print(\"Second element clean:\")\n",
        "print(clean_train_x[1])\n",
        "print(\"Second element with top 10 features:\")\n",
        "print(top100_train_x[1])\n",
        "print(\"--------------------------------------------------------------------\")\n",
        "print(\"Third element clean:\")\n",
        "print(clean_train_x[2])\n",
        "print(\"Third element with top 10 features:\")\n",
        "print(top100_train_x[2])"
      ],
      "metadata": {
        "id": "EvhhKuZpiqJo",
        "outputId": "9a9193a1-959b-43b2-9c26-d914dc5ed336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First element clean:\n",
            "['subject', 'thank', 'ami', 'daren', 'want', 'say', 'thank', 'great', 'time', 'st', 'pete', 'beach', 'fla', 'compani', 'food', 'fish', 'ye', 'coars', 'drink', 'mani', 'drink', 'great', 'daren', 'relat', 'drink', 'enjoy', 'meet', 'everyon', 'appreci', 'busi', 'look', 'forward', 'continu', 'busi', 'relat', 'enron', 'futur', 'sincer', 'tim']\n",
            "First element with top 10 features:\n",
            "['subject', 'thank', 'daren', 'want', 'thank', 'time', 'compani', 'daren', 'busi', 'look', 'forward', 'busi', 'enron']\n",
            "--------------------------------------------------------------------\n",
            "Second element clean:\n",
            "['subject', 'spot', 'firm', 'ticket', 'vanc', 'follow', 'nomin', 'deal', 'ticket', 'sitara', 'septemb', 'activ', 'plea', 'advis', 'whether', 'deal', 'spot', 'firm', 'daren', 'want', 'everyth', 'sitara', 'pm', 'monday', 'august', 'thank', 'bob', 'sourc', 'meter', 'sept', 'nom', 'ccgm', 'lp', 'cross', 'tex', 'cummin', 'walker', 'unk', 'dalla', 'product', 'duke', 'energi', 'trade', 'eex', 'oper', 'eog', 'resourc', 'hesco', 'gather', 'hesco', 'gather', 'ph', 'explor', 'pioneer', 'explor', 'pure', 'resourc', 'rio', 'vista', 'samson', 'lonestar', 'swift', 'energi', 'tema', 'oil', 'ga', 'tri', 'union', 'develop', 'white', 'petroleum']\n",
            "Second element with top 10 features:\n",
            "['subject', 'ticket', 'follow', 'nomin', 'deal', 'ticket', 'sitara', 'plea', 'deal', 'daren', 'want', 'sitara', 'pm', 'thank', 'bob', 'meter', 'nom', 'product', 'energi', 'energi', 'ga']\n",
            "--------------------------------------------------------------------\n",
            "Third element clean:\n",
            "['subject', 'softwar', 'microsoft', 'window', 'xp', 'professiozn', 'retail', 'price', 'low', 'prici', 'save', 'adob', 'photoshkop', 'retail', 'price', 'low', 'price', 'savu', 'microsoft', 'offic', 'xp', 'profession', 'retail', 'price', 'low', 'price', 'savx', 'adob', 'illustr', 'retaitl', 'price', 'low', 'price', 'savx', 'corel', 'draw', 'graphic', 'suit', 'rehtail', 'price', 'low', 'pricj', 'save', 'delphi', 'retaifl', 'price', 'low', 'price', 'save', 'cheap', 'softwar', 'oem', 'meaninag', 'get', 'box', 'manual', 'softwar', 'receivz', 'actual', 'softwar', 'uniqu', 'registr', 'code', 'softwaru', 'english', 'languag', 'pc', 'offer', 'unbeatablk', 'alway', 'updat', 'price', 'make', 'sure', 'provid', 'besft', 'possibl', 'offer', 'hurri', 'place', 'ordner', 'suppli', 'limit', 'visimt', 'u', 'http', 'cheap', 'drug', 'biz', 'oeol', 'affili', 'id', 'campaign', 'id', 'fwunrt', 'fmooetr', 'ltbi', 'nyqkgbphb', 'krgzgl', 'vbbmigb', 'zwftnqlp', 'oaohkv', 'icckmv', 'rmcetdf', 'wmlx', 'lidfxvrnk', 'tdrezc', 'hbmvxft', 'zjqdpnpd', 'ldloti', 'jbywub', 'ozaqgcf', 'czjj', 'yvcbkprnc', 'vbrekd', 'fizzjnz', 'kgfmkhmw', 'rkqumd', 'kgrnbt', 'ggejkmi', 'kyyj', 'jepyoyklp', 'wekjhw', 'pajrtqi', 'ybjlkvjj', 'gvnwte', 'ueqjbv', 'vkcrccd', 'uwut', 'uwdhtzrrf', 'mhbglw', 'jdhkydx', 'bvaeyvat', 'nvorcx', 'qvpwtx', 'yniuzlb', 'kkei', 'lziqyfqqu', 'mhlped', 'kuauryt', 'bthnutaz', 'clzkex', 'pvojiw', 'xaablvb', 'gnao', 'otxenpenr', 'qmdvju', 'qafbwcc', 'xdntfvhf', 'jxzhbn']\n",
            "Third element with top 10 features:\n",
            "['subject', 'price', 'price', 'price', 'price', 'price', 'price', 'price', 'price', 'price', 'price', 'get', 'actual', 'price', 'make', 'u', 'http']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive base model \n",
        "count_vector = CountVectorizer()\n",
        "\n",
        "top100_train_x_join = [\" \".join(i) for i in top100_train_x] #turn to string for count_vector \n",
        "\n",
        "trans_x = count_vector.fit_transform(top100_train_x_join)\n",
        "\n",
        "trans_x_dense = np.array(trans_x.todense())\n",
        "\n",
        "Model3 = MultinomialNB().fit(trans_x_dense,train_y) #multi ???"
      ],
      "metadata": {
        "id": "Gxe57aS_jPMb"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes model removing 100 most frequent words from features "
      ],
      "metadata": {
        "id": "8OYkzmeADXSf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c4OlKHzbDfXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes model using subject line as the feature set"
      ],
      "metadata": {
        "id": "55ba6XwwDjuW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aAep9kIeDnLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation using validation set"
      ],
      "metadata": {
        "id": "loNqoBygDvj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the evaluation metrics"
      ],
      "metadata": {
        "id": "vXrPDXCRDyPj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6WdjW_G3Dwzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing all 5 models "
      ],
      "metadata": {
        "id": "-ojjfOmHDxP7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xgs1FOVmD3ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommended model and reasons"
      ],
      "metadata": {
        "id": "NWlXiwfID4eR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkhnImSAD741"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation using test set"
      ],
      "metadata": {
        "id": "twjWz8S2D8aO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KO1zZytfECtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Is recommendation still valid?"
      ],
      "metadata": {
        "id": "ChR2iLqsEDOT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oE91jfWsEFh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of 1 more variation to improve performance "
      ],
      "metadata": {
        "id": "_0kOaI7vEGFA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bebIFA3bEOju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of improved model"
      ],
      "metadata": {
        "id": "03venv1LEPGh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3NnOGM9vERIi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}